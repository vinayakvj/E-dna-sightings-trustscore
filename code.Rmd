---
title: "Untitled"
author: "Sweta Manjaly"
date: "2025-10-04"
output: html_document
---

```{r 1}
library(dplyr)
library(readr)
library(stringr)
library(tidyr)
library(tibble)
library(purrr)
library(rlang)

# ---- INPUTS ----
file_path <- "C:/Users/rosam/Downloads/all_voyages.csv/all_voyages.csv"

# Read
df <- read.csv(file_path, stringsAsFactors = FALSE, check.names = FALSE)

# Quick peeks
head(df)
str(df)
summary(df)
names(df)

# Missingness
colSums(is.na(df))

na_report <- tibble(
  column      = names(df),
  n_missing   = colSums(is.na(df)),
  pct_missing = round(100 * colMeans(is.na(df)), 1)
) |>
  arrange(desc(n_missing))
na_report

```
```{r 2}
library(dplyr)
library(rlang)
library(stringr)

# columns we want if they exist
want_cols  <- c(
  "ASV_sequence", "X.ID", "count",
  "order", "family", "genus", "species", "LCA",
  "decimalLatitude", "decimalLongitude",
  "assay_name", "Assay", "Gene",
  "ASV", "sample", "Species_In_LCA"
)

assay_cols <- c("assay_name","Assay","Gene")

result_tbl <- df %>%
  select(any_of(want_cols)) %>%
  mutate(
    # safe: check if column exists
    percent_id = if ("X.ID" %in% names(df)) .data$X.ID else NA_real_,

    # unify LCA
    LCA = coalesce(.data$LCA, .data$Species_In_LCA),

    # coalesce across whichever assay columns are present
    assay = {
      cols <- intersect(assay_cols, names(df))
      if (length(cols)) {
        do.call(coalesce, df[cols])
      } else {
        NA_character_
      }
    }
  ) %>%
  select(
    any_of(c("ASV","sample")),
    ASV_sequence, count, percent_id,
    order, family, genus, species, LCA,
    decimalLatitude, decimalLongitude,
    assay
  )

# Clean up characters (trim, blank->NA), drop all-NA cols
result_tbl[] <- lapply(result_tbl, function(x) {
  if (is.character(x)) {
    x <- trimws(x)
    x[x == ""] <- NA
  }
  x
})
result_tbl <- result_tbl[, vapply(result_tbl, function(x) !all(is.na(x)), logical(1L)), drop = FALSE]

# Unique counts per column
sapply(result_tbl, function(x) length(unique(x)))

# Standardise snake_case
names(result_tbl) <- tolower(gsub("\\s+", "_", names(result_tbl)))

# Save cleaned table
#write.csv(result_tbl, "cleaned_data.csv", row.names = FALSE)

```

```{r 3}
# FAST AUS BOX + PREFILTER FOR BIG DATA
#

suppressPackageStartupMessages({
  library(sf)
  library(dplyr)
})

# ---- Step 1: Simple Rough Australia Bounding Box ----
get_aus_box_fast <- function() {
  message("üåè Using rough Australia bbox fallback.")

  # Define the approximate bounding box coordinates
  # xmin = 105¬∞E, ymin = -46¬∞S, xmax = 170¬∞E, ymax = -8¬∞S
  # This rectangle covers the entire Australian continent and nearby waters.
  approx_bbox <- c(105, -46, 170, -8)

  # Step 2: Build a rectangular polygon using those coordinates
  bb_poly <- st_polygon(list(rbind(
    c(approx_bbox[1], approx_bbox[2]),  # lower-left
    c(approx_bbox[3], approx_bbox[2]),  # lower-right
    c(approx_bbox[3], approx_bbox[4]),  # upper-right
    c(approx_bbox[1], approx_bbox[4]),  # upper-left
    c(approx_bbox[1], approx_bbox[2])   # close polygon
  )))

  # Step 3: Convert to a proper sf spatial object (WGS84 coordinate system)
  aus_bbox <- st_as_sf(st_sfc(bb_poly, crs = 4326))
  return(aus_bbox)
}

# ---- Step 4: Create the bounding box polygon ----
aus_box <- get_aus_box_fast()

# ---- Step 5: Prefilter your dataset quickly ----
# Assumes your dataframe is named `df` and includes decimalLongitude / decimalLatitude columns.
# First, extract the bounding box limits for numeric filtering.
bb <- sf::st_bbox(aus_box)

# Step 6: Use a simple rectangular filter to remove coordinates outside the box.
# This is the fastest possible spatial filter before doing expensive geometry joins.
df_fast <- df %>%
  dplyr::filter(
    !is.na(decimalLongitude), !is.na(decimalLatitude),
    decimalLongitude >= bb["xmin"],
    decimalLongitude <= bb["xmax"],
    decimalLatitude  >= bb["ymin"],
    decimalLatitude  <= bb["ymax"]
  )

# Step 7: Convert the remaining rows into sf points (spatial objects)
pts_fast <- sf::st_as_sf(
  df_fast,
  coords = c("decimalLongitude", "decimalLatitude"),
  crs = 4326,
  remove = FALSE
)

# Step 8: Keep only those points that lie within the Australia bounding box polygon
pts_in_aus <- sf::st_join(pts_fast, aus_box, left = FALSE)

# Step 9: Convert back to a plain dataframe so it‚Äôs easy to handle later
rows_in_aus <- df_fast[as.integer(rownames(pts_in_aus)), , drop = FALSE]

# ---- Step 10: Print quick summary counts ----
# These counts help verify how many rows were kept at each stage.
cat("# rows original:   ", nrow(df),        "\n")
cat("# rows bbox-pass:  ", nrow(df_fast),   "\n")
cat("# rows inside AUS: ", nrow(pts_in_aus), "\n")




```

```{r}

# OBIS-only workflow: measure how close each sample is to known occurrences
# ----------------------------------------------------------------------------
# What this script does :
# 1) Builds an ‚ÄúArea of Interest‚Äù (AOI) around your sampling sites in Australia
#    using a convex hull + a safety buffer (so we include nearby waters).
# 2) Extracts clean candidate species names from your data (Species + LCA list).
# 3) Resolves each species to a stable WoRMS AphiaID (handles synonyms, typos).
# 4) Fetches occurrence points for each species from OBIS (cached on disk).
# 5) For every sample, computes the nearest distance to any OBIS record of its
#    candidate species (and flags within 20/50/100 km).
# 6) Summarises distances overall and per species, and saves tidy CSV outputs.
##############################################################################

suppressPackageStartupMessages({
  library(dplyr); library(tidyr); library(stringr); library(purrr); library(tibble)
  library(sf); library(geosphere); library(robis); library(readr); library(worrms)
})

# Expect an input data.frame `df` with decimalLongitude/decimalLatitude,
# species, and/or Species_In_LCA columns available.

###############################################################################
# 1Ô∏è‚É£  DEFINE AREA OF INTEREST (AOI)
# ----------------------------------------------------------------------------
# Buffer distance is parameterised; change via options(obis_aoi_buffer_km = 100)
# CRS and cache dir can also be tweaked via options().
###############################################################################

buffer_km <- getOption("obis_aoi_buffer_km", 100)   # default 100 km
aoi_crs_m <- getOption("obis_aoi_crs", 3577)       # EPSG:3577 (Australia Albers, metres)
simplify_tolerance_deg <- getOption("obis_aoi_simplify_deg", 0.00) # e.g., 0.01 ‚âà ~1 km

# Turn your rows into spatial points if you don‚Äôt already have `pts_in_aus`.
pts_wgs84 <- if (exists("pts_in_aus")) {
  pts_in_aus
} else {
  sf::st_as_sf(df, coords = c("decimalLongitude","decimalLatitude"),
               crs = 4326, remove = FALSE)
}

# Defensive filtering of obviously invalid coordinates
pts_wgs84 <- pts_wgs84 %>%
  dplyr::filter(
    !is.na(decimalLongitude), !is.na(decimalLatitude),
    decimalLongitude >= -180, decimalLongitude <= 180,
    decimalLatitude  >=  -90, decimalLatitude  <=  90
  )

# Build hull ‚Üí buffer ‚Üí convert back to WGS84 (lon/lat) ‚Üí export as WKT text.
pts_aea   <- sf::st_transform(pts_wgs84, aoi_crs_m)
u         <- sf::st_union(pts_aea)
# Fallback to union if convex hull fails (e.g., single point)
hull_aea  <- tryCatch(sf::st_convex_hull(u), error = function(e) u)
aoi_aea   <- sf::st_make_valid(sf::st_buffer(hull_aea, dist = buffer_km * 1000))
aoi_wgs84 <- sf::st_zm(sf::st_transform(aoi_aea, 4326))

# Optional: simplify AOI to speed WKT handling (0 disables)
if (simplify_tolerance_deg > 0) {
  aoi_wgs84 <- sf::st_simplify(aoi_wgs84, dTolerance = simplify_tolerance_deg)
}

aoi_wkt   <- sf::st_as_text(aoi_wgs84)   # OBIS understands WKT strings

###############################################################################
# 2Ô∏è‚É£  PREPARE FLAT DATA
# ----------------------------------------------------------------------------

data_obis <- if (exists("rows_in_aus")) rows_in_aus else if (exists("pts_in_aus")) {
  sf::st_drop_geometry(pts_in_aus)
} else sf::st_drop_geometry(pts_wgs84)

# Ensure required columns exist and have the right type.
for (nm in c("species","Species_In_LCA")) {
  if (!nm %in% names(data_obis)) data_obis[[nm]] <- NA_character_
  data_obis[[nm]] <- as.character(data_obis[[nm]])
}
for (nm in c("decimalLongitude","decimalLatitude")) {
  if (!nm %in% names(data_obis)) data_obis[[nm]] <- NA_real_
}

###############################################################################
# 3Ô∏è‚É£  EXTRACT CANDIDATE SPECIES NAMES (binomials only)
# ----------------------------------------------------------------------------

`%||%` <- function(a,b) if (!is.null(a)) a else b
is_binomial <- function(x) is.character(x) && nzchar(x) && grepl("\\S+\\s+\\S+", x)

extract_candidates <- function(species, Species_In_LCA) {
  sp  <- str_squish(species %||% "")
  sil <- str_squish(Species_In_LCA %||% "")
  if (!identical(tolower(sp), "dropped") && is_binomial(sp)) return(sp)
  if (nzchar(sil)) {
    cand <- str_split(sil, ",")[[1]] |> str_squish()
    cand <- cand[grepl("\\S+\\s+\\S+", cand)] |> unique()
    if (length(cand)) return(cand)
  }
  character(0)
}

data_obis$candidates <- pmap(
  data_obis[, c("species","Species_In_LCA")],
  extract_candidates
)

# De-duplicate candidate lists (micro-optimisation for fewer OBIS calls)
data_obis$candidates <- purrr::map(data_obis$candidates, ~ unique(.x[nchar(.x) > 0]))

###############################################################################
# 4Ô∏è‚É£  RESOLVE WORMS APHIAID + FETCH OBIS RECORDS (with caching)
# ----------------------------------------------------------------------------

# In-memory cache for AphiaID lookups.
.aphia_cache <- new.env(parent = emptyenv())

resolve_aphia <- function(scientific_name) {
  if (!nzchar(scientific_name)) return(NA_integer_)
  key <- tolower(scientific_name)
  if (exists(key, envir = .aphia_cache, inherits = FALSE)) return(get(key, .aphia_cache))

  id <- NA_integer_
  # Try exact first; if that fails, pull candidate records and prefer accepted species.
  exact <- tryCatch(wm_name2id(scientificname = scientific_name), error = function(e) NA_integer_)
  if (!is.na(exact)) {
    id <- suppressWarnings(as.integer(exact))
  } else {
    recs <- tryCatch(wm_records_name(name = scientific_name), error = function(e) NULL)
    if (!is.null(recs) && length(recs)) {
      df <- tibble::as_tibble(recs)
      df <- df %>% arrange(desc(status == "accepted"), desc(rank == "Species"))
      id <- suppressWarnings(as.integer(df$AphiaID[1]))
    }
  }
  assign(key, id, envir = .aphia_cache)
  id
}

# Explicit, configurable cache directory for per-species OBIS CSVs
occ_dir <- getOption("obis_occ_dir", "../Data/SpeciesPoints_OBIS")
dir.create(occ_dir, showWarnings = FALSE, recursive = TRUE)

# Gentle wrapper to handle OBIS hiccups quietly
safe_occurrence <- function(...) tryCatch(robis::occurrence(...), error = function(e) NULL)

# Get OBIS occurrence points for one species: AOI first; if empty, try global.
get_species_points_obis <- function(sp, wkt = NULL) {
  if (!nzchar(sp)) return(tibble())
  safe <- gsub("[^A-Za-z0-9_]+","_", sp)
  out_path <- file.path(occ_dir, paste0(safe, ".csv"))

  # Reuse cached CSV if present.
  if (file.exists(out_path)) {
    df <- suppressMessages(readr::read_csv(out_path, show_col_types = FALSE))
    return(df %>% filter(!is.na(decimalLongitude), !is.na(decimalLatitude)))
  }

  fetch_once <- function(geom = NULL, aphia = NA_integer_) {
    if (!is.na(aphia)) safe_occurrence(taxonid = aphia, geometry = geom)
    else               safe_occurrence(scientificname = sp, geometry = geom)
  }

  aphia <- resolve_aphia(sp)

  # Prefer AOI-constrained fetch to keep results tight; fall back to global if empty.
  ob <- fetch_once(wkt, aphia)
  if (is.null(ob) || !nrow(ob)) ob <- fetch_once(NULL, aphia)

  # If still empty, write an empty CSV so we don‚Äôt retry this species repeatedly.
  if (is.null(ob) || !nrow(ob)) {
    readr::write_csv(tibble(species = character(), decimalLongitude = double(), decimalLatitude = double()),
                     out_path)
    return(tibble())
  }

  df <- ob %>%
    transmute(
      species          = sp,
      decimalLongitude = suppressWarnings(as.numeric(decimalLongitude)),
      decimalLatitude  = suppressWarnings(as.numeric(decimalLatitude))
    ) %>%
    filter(!is.na(decimalLongitude), !is.na(decimalLatitude)) %>%
    distinct()

  readr::write_csv(df, out_path)

  # small politeness pause to be nice to OBIS
  Sys.sleep(getOption("obis_pause_sec", 0.1))

  df
}

###############################################################################
# 5Ô∏è‚É£  BUILD SPECIES LIST + LIGHTWEIGHT INDEX
# ----------------------------------------------------------------------------

uniq_species <- unique(unlist(data_obis$candidates, use.names = FALSE))
uniq_species <- uniq_species[nzchar(uniq_species)]

message("Unique species (OBIS-only) to fetch: ", length(uniq_species))

index_tbl <- tibble(candidate = uniq_species) %>%
  mutate(n_rows = map_int(candidate, ~ nrow(get_species_points_obis(.x, aoi_wkt))))
readr::write_csv(index_tbl, file.path(occ_dir, "_index.csv"))

###############################################################################
###############################################################################
# 6) NEAREST-DISTANCE CALCULATION PER SAMPLE
# ----------------------------------------------------------------------------
# - nearest_obis_m:        minimum distance (metres) to any candidate's OBIS point
# - nearest_obis_min_km:   same as above, in kilometres (rounded)
# - nearest_obis_all_km:   comma-separated per-candidate minimum distances (km),
#                          in the SAME ORDER as `candidates` / Species_In_LCA
# - obis_within_*km:       TRUE/FALSE using the minimum distance
# - obis_within_*km_all:   comma-separated TRUE/FALSE per candidate (optional)
###############################################################################

# Small in-memory cache so we don't re-read the same species CSV repeatedly
.pts_cache <- new.env(parent = emptyenv())
get_cached_pts <- function(sp) {
  if (exists(sp, envir = .pts_cache, inherits = FALSE)) return(get(sp, .pts_cache))
  df <- get_species_points_obis(sp, aoi_wkt)
  assign(sp, df, envir = .pts_cache)
  df
}

# Minimum distance (metres) from a sample to ANY of the candidates' OBIS points
dist_min_m <- function(sample_lon, sample_lat, species_vec) {
  if (is.na(sample_lon) || is.na(sample_lat) || length(species_vec) == 0) return(NA_real_)
  ref <- c(sample_lon, sample_lat) # (lon, lat)

  mins <- purrr::map_dbl(species_vec, function(sp) {
    pts <- get_cached_pts(sp)
    if (!nrow(pts)) return(Inf)
    geosphere::distHaversine(
      as.matrix(pts[, c("decimalLongitude","decimalLatitude")]),
      ref
    ) |> min(na.rm = TRUE)
  })

  d <- suppressWarnings(min(mins, na.rm = TRUE))
  if (is.infinite(d)) NA_real_ else d
}

# Per-candidate minimum distances (kilometres), preserving the input order
dist_each_km <- function(sample_lon, sample_lat, species_vec) {
  if (is.na(sample_lon) || is.na(sample_lat) || length(species_vec) == 0) return(numeric(0))
  ref <- c(sample_lon, sample_lat)

  purrr::map_dbl(species_vec, function(sp) {
    pts <- get_cached_pts(sp)
    if (!nrow(pts)) return(Inf)
    m <- geosphere::distHaversine(
      as.matrix(pts[, c("decimalLongitude","decimalLatitude")]),
      ref
    ) |> min(na.rm = TRUE)
    m / 1000  # km
  })
}

# Compute min distance and per-candidate distances
data_obis$nearest_obis_m <- mapply(
  dist_min_m,
  data_obis$decimalLongitude,
  data_obis$decimalLatitude,
  data_obis$candidates,
  SIMPLIFY = TRUE
)

data_obis$nearest_obis_all_km <- mapply(
  function(lon, lat, vec) {
    d <- dist_each_km(lon, lat, vec)
    if (!length(d)) return(NA_character_)
    paste0(round(d, 2), collapse = ",")
  },
  data_obis$decimalLongitude,
  data_obis$decimalLatitude,
  data_obis$candidates,
  SIMPLIFY = TRUE
)

# Convenience flags: min-distance thresholds (as before)
data_obis <- data_obis %>%
  dplyr::mutate(
    nearest_obis_min_km = round(nearest_obis_m / 1000, 2),
    obis_within_20km    = nearest_obis_m <  20e3,
    obis_within_50km    = nearest_obis_m <  50e3,
    obis_within_100km   = nearest_obis_m < 100e3
  )

# OPTIONAL: per-candidate TRUE/FALSE strings for the same thresholds,
# aligned with the order in `nearest_obis_all_km` / `candidates`.
split_to_num <- function(x) {
  if (is.na(x) || !nzchar(x)) return(numeric(0))
  as.numeric(strsplit(x, ",", fixed = TRUE)[[1]])
}
mk_flag_str <- function(km_str, cutoff_km) {
  d <- split_to_num(km_str)
  if (!length(d)) return(NA_character_)
  paste0(ifelse(is.finite(d) & d < cutoff_km, "TRUE", "FALSE"), collapse = ",")
}

data_obis <- data_obis %>%
  dplyr::mutate(
    obis_within_20km_all  = vapply(nearest_obis_all_km, mk_flag_str, character(1), cutoff_km = 20),
    obis_within_50km_all  = vapply(nearest_obis_all_km, mk_flag_str, character(1), cutoff_km = 50),
    obis_within_100km_all = vapply(nearest_obis_all_km, mk_flag_str, character(1), cutoff_km = 100)
  )

###############################################################################
#  7Ô∏è‚É£  SUMMARIES: OVERALL + PER-SPECIES QUANTILES
# ----------------------------------------------------------------------------

overall_50pct_km <- stats::quantile(data_obis$nearest_obis_m, 0.5, na.rm = TRUE) / 1000
message(sprintf("Overall 50%% probability distance (OBIS-only): %.1f km", overall_50pct_km))

first_binomial <- function(cands) { x <- cands[grepl("\\S+\\s+\\S+", cands)]; if (length(x)) x[1] else NA_character_ }
data_obis$primary_candidate <- vapply(data_obis$candidates, first_binomial, character(1))

per_species_quant_obis <- data_obis %>%
  filter(!is.na(nearest_obis_m), !is.na(primary_candidate)) %>%
  group_by(primary_candidate) %>%
  summarise(
    n_rows = dplyr::n(),
    p50_km = quantile(nearest_obis_m, 0.5, na.rm = TRUE) / 1000,
    p80_km = quantile(nearest_obis_m, 0.8, na.rm = TRUE) / 1000,
    p95_km = quantile(nearest_obis_m, 0.95, na.rm = TRUE) / 1000,
    .groups = "drop"
  ) %>%
  arrange(desc(n_rows))

###############################################################################
# 8Ô∏è‚É£  SAVE OUTPUTS + LIGHT DIAGNOSTICS
# ----------------------------------------------------------------------------

readr::write_csv(data_obis,              "../Data/data_OBIS_enriched_distances.csv")
readr::write_csv(per_species_quant_obis, "../Data/OBIS_distance_quantiles_per_species.csv")

cat("\nExample candidates (first 3 rows):\n"); print(head(data_obis$candidates, 3))
if (length(uniq_species)) {
  test_sp <- uniq_species[1]; tmp <- get_cached_pts(test_sp)
  cat("\nTest species (OBIS-only):", test_sp, "->", nrow(tmp), "points\n"); print(head(tmp, 3))
}
cat(sprintf("\nRows with OBIS distances: %d / %d\n",
            sum(!is.na(data_obis$nearest_obis_m)), nrow(data_obis)))
summary(data_obis$nearest_obis_m)



```

```{r fishbase_obis_evidence}
# ================================================================
# CONTINUATION: FishBase + OBIS evidence for Australia
# ---------------------------------------------------------------
suppressPackageStartupMessages({
  library(dplyr); library(readr); library(stringr); library(tidyr)
  library(tibble); library(purrr); library(arrow); library(sf)
})

# ---------- Use existing Australia polygon / OBIS cache if available ----------
if (!exists("aus_box")) {
  # fast rectangular fallback (same as earlier bbox)
  get_aus_box_fast <- function() {
    approx_bbox <- c(105, -46, 170, -8)  # xmin, ymin, xmax, ymax
    bb_poly <- st_polygon(list(rbind(
      c(approx_bbox[1], approx_bbox[2]),
      c(approx_bbox[3], approx_bbox[2]),
      c(approx_bbox[3], approx_bbox[4]),
      c(approx_bbox[1], approx_bbox[4]),
      c(approx_bbox[1], approx_bbox[2])
    )))
    st_as_sf(st_sfc(bb_poly, crs = 4326))
  }
  aus_box <- get_aus_box_fast()
}

occ_dir <- getOption("obis_occ_dir", "../Data/SpeciesPoints_OBIS")
dir.create(occ_dir, showWarnings = FALSE, recursive = TRUE)

# ---------- Pick a source table that actually exists ----------
# Prefer rows filtered to Australia if you ran the bbox step; else fall back to df/result_tbl.
src <- if (exists("rows_in_aus")) {
  rows_in_aus
} else if (exists("result_tbl")) {
  result_tbl
} else {
  df
}

# Helper to safely pick the first existing column name from a set
pick_col <- function(dat, candidates) {
  nm <- intersect(candidates, names(dat))[1]
  if (is.na(nm)) NULL else nm
}

# Identify column names for species list and ASV/sample (handles both original and snake_case)
col_species_lca <- pick_col(src, c("Species_In_LCA","species_in_lca","LCA","lca","species"))
col_asv         <- pick_col(src, c("ASV","asv"))
col_sample      <- pick_col(src, c("sample","Sample","SAMPLE"))

# If no species column exists, create an empty one to keep pipeline robust
if (is.null(col_species_lca)) {
  src$Species_In_LCA <- NA_character_
  col_species_lca <- "Species_In_LCA"
}

# ---------- Build unique, well-formed candidate names (binomials) ----------
# Vectorized: returns a logical vector the same length as x
is_binomial <- function(x) {
  x <- as.character(x)
  !is.na(x) & nzchar(x) & grepl("\\S+\\s+\\S+", x)
}

all_candidates <- src %>%
  transmute(Species_In_LCA = .data[[col_species_lca]]) %>%
  filter(!is.na(Species_In_LCA), nzchar(Species_In_LCA)) %>%
  separate_rows(Species_In_LCA, sep = ",") %>%
  mutate(candidate = stringr::str_squish(Species_In_LCA)) %>%
  filter(is_binomial(candidate)) %>%
  distinct(candidate)


# Shortcut: if you already wrote per-species OBIS CSVs in occ_dir, we can
# check AU presence by intersecting those cached points with aus_box.
# If a CSV is missing, we treat it as zero hits (you can run the OBIS fetcher first).

read_cached_obis <- function(sp, occ_dir) {
  safe <- gsub("[^A-Za-z0-9_]+","_", sp)
  path <- file.path(occ_dir, paste0(safe, ".csv"))
  if (!file.exists(path)) return(tibble(decimalLongitude = numeric(), decimalLatitude = numeric()))
  suppressMessages(readr::read_csv(path, show_col_types = FALSE)) %>%
    filter(!is.na(decimalLongitude), !is.na(decimalLatitude))
}

obis_hits_in_aus_box <- function(sp, aus_poly, occ_dir) {
  pts <- read_cached_obis(sp, occ_dir)
  if (!nrow(pts)) return(0L)
  sfpts <- sf::st_as_sf(pts, coords = c("decimalLongitude","decimalLatitude"), crs = 4326, remove = FALSE)
  sfpts <- suppressWarnings(sf::st_make_valid(sfpts))
  hits  <- suppressWarnings(sf::st_intersects(sfpts, aus_poly, sparse = TRUE))
  sum(lengths(hits) > 0L)
}

# ---------- FishBase country presence (AU) via parquet mirrors ----------
cache_dir <- "fishbase_cache"; dir.create(cache_dir, showWarnings = FALSE)

dl <- function(url, fname) {
  path <- file.path(cache_dir, fname)
  if (!file.exists(path)) download.file(url, path, mode = "wb", quiet = TRUE)
  path
}

species_path <- dl(
  "https://huggingface.co/datasets/cboettig/fishbase/resolve/main/data/fb/v24.07/parquet/species.parquet?download=true",
  "species.parquet"
)
syn_path <- dl(
  "https://huggingface.co/datasets/cboettig/fishbase/resolve/main/data/fb/v24.07/parquet/synonyms.parquet?download=true",
  "synonyms.parquet"
)
country_path <- dl(
  "https://huggingface.co/datasets/cboettig/fishbase/resolve/main/data/fb/v24.07/parquet/country.parquet?download=true",
  "country.parquet"
)

species_df <- read_parquet(species_path) %>% select(SpecCode, Genus, Species)
syn_df     <- read_parquet(syn_path)     %>% select(SpecCode, SynGenus, SynSpecies)
country_df <- read_parquet(country_path)

spec_col  <- grep("spec",  names(country_df), ignore.case = TRUE, value = TRUE)[1]
ccode_col <- grep("c[_]?code", names(country_df), ignore.case = TRUE, value = TRUE)[1]

country_df <- country_df %>% select(SpecCode = all_of(spec_col), C_Code = all_of(ccode_col))
au_df      <- country_df %>% filter(C_Code %in% c(36, "36", "036"))

name_to_speccode <- function(sciname) {
  if (is.na(sciname) || !nzchar(sciname) || !grepl("\\s", sciname)) return(NA_integer_)
  parts <- str_split(sciname, "\\s+", n = 2, simplify = TRUE)
  G <- parts[1,1]; S <- parts[1,2]
  hit <- species_df %>% filter(Genus == G, Species == S) %>% slice_head(n = 1)
  if (nrow(hit) == 1) return(hit$SpecCode[[1]])
  syn <- syn_df %>% filter(SynGenus == G, SynSpecies == S) %>% slice_head(n = 1)
  if (nrow(syn) == 1) return(syn$SpecCode[[1]])
  NA_integer_
}
is_in_au <- function(code) if (is.na(code)) NA else any(au_df$SpecCode == code)

# ---------- Build the truth table (one row per species) ----------
species_truth <- all_candidates %>%
  mutate(
    SpecCode       = map_int(candidate, name_to_speccode),
    fb_in_AU       = map_lgl(SpecCode, is_in_au),
    obis_hits_AU   = map_int(candidate, ~ obis_hits_in_aus_box(.x, aus_box, occ_dir)),
    obis_in_AU     = obis_hits_AU > 0L,
    any_evidence   = fb_in_AU | obis_in_AU
  ) %>%
  select(candidate, SpecCode, fb_in_AU, obis_in_AU, obis_hits_AU, any_evidence) %>%
  arrange(desc(any_evidence), desc(obis_hits_AU), desc(fb_in_AU), candidate)

readr::write_csv(species_truth, "species_in_LCA_truth_table.csv")

# ---------- Expand back to per-row ◊ candidate ----------
per_row_truth <- src %>%
  mutate(row_id = dplyr::row_number()) %>%
  transmute(
    row_id,
    ASV    = if (!is.null(col_asv))    .data[[col_asv]]    else NA,
    sample = if (!is.null(col_sample)) .data[[col_sample]] else NA,
    Species_In_LCA = .data[[col_species_lca]]
  ) %>%
  filter(!is.na(Species_In_LCA), nzchar(Species_In_LCA)) %>%
  separate_rows(Species_In_LCA, sep = ",") %>%
  mutate(candidate = str_squish(Species_In_LCA)) %>%
  filter(is_binomial(candidate)) %>%
  left_join(species_truth, by = "candidate") %>%
  select(row_id, ASV, sample, candidate, fb_in_AU, obis_in_AU, obis_hits_AU, any_evidence)

readr::write_csv(per_row_truth, "species_in_LCA_truth_per_row.csv")

# ---------- Quick diagnostics ----------
cat("\n# unique candidates:", nrow(species_truth), "\n")
print(head(species_truth, 10))
cat("\n# per-row ◊ candidate rows:", nrow(per_row_truth), "\n")
print(head(per_row_truth, 10))
# ================================================================

```

